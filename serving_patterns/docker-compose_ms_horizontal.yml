version: '3'

services:
  ms_horizontal_inceptionv3_api:
    container_name: serving_patterns_ms_horizontal_ineptionv3_api
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile_api_inceptionv3
    environment:
      - PLATFORM=docker_compose
      - MODEL_INTERFACE=inceptionv3.yaml
      - GUNICORN_UVICORN=GUNICORN
      - WORKERS=4
      - APP_NAME=app.apps.app_image:app
      - PORT=8892
      - TFS_GRPC=ms_horizontal_inceptionv3_tfs:8500
      - PROFILE=0
      - QUEUE_NAME=inceptionv2_queue
    ports:
      - "8892:8892"
    command: ./run_api.sh
    volumes:
      - shared_volume:/shared_volume
    depends_on:
      - redis
      - ms_horizontal_inceptionv3_tfs
      - ms_horizontal_inceptionv3_backend

  ms_horizontal_inceptionv3_tfs:
    container_name: serving_patterns_ms_horizontal_ineptionv3_tfs
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile_tfserving_inceptionv3
    environment:
      - PORT=8500
      - REST_API_PORT=8501
      - MODEL_NAME=inceptionv3
      - MODEL_BASE_PATH=/models/inceptionv3
    ports:
      - "8500:8500"
      - "8501:8501"
    entrypoint: ["/usr/bin/tf_serving_entrypoint.sh"]

  ms_horizontal_inceptionv3_backend:
    container_name: serving_patterns_ms_horizontal_ineptionv3_backend
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile_backend_inceptionv3
    environment:
      - PLATFORM=docker_compose
      - MODEL_INTERFACE=inceptionv3.yaml
      - NUM_PROCS=4
      - BATCH_CODE=app.backend.prediction_batch
      - TFS_GRPC=ms_horizontal_inceptionv3_tfs:8500
      - PROFILE=0
      - PREDICTOR=app.api._predict_image
      - QUEUE_NAME=inceptionv2_queue
    command: ./run_backend.sh
    volumes:
      - shared_volume:/shared_volume
    depends_on:
      - redis

  ms_horizontal_mobilenetv2_api:
    container_name: serving_patterns_ms_horizontal_mobilenetv2_api
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile_api_mobilenetv2
    environment:
      - PLATFORM=docker_compose
      - MODEL_INTERFACE=mobilenetv2.yaml
      - GUNICORN_UVICORN=GUNICORN
      - WORKERS=4
      - APP_NAME=app.apps.app_image:app
      - PORT=8893
      - TFS_GRPC=ms_horizontal_mobilenetv2_tfs:8510
      - PROFILE=0
      - QUEUE_NAME=mobilenetv2_queue
    ports:
      - "8893:8893"
    command: ./run_api.sh
    volumes:
      - shared_volume:/shared_volume
    depends_on:
      - redis
      - ms_horizontal_mobilenetv2_tfs
      - ms_horizontal_mobilenetv2_backend

  ms_horizontal_mobilenetv2_tfs:
    container_name: serving_patterns_ms_horizontal_mobilenetv2_tfs
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile_tfserving_mobilenetv2
    environment:
      - PORT=8510
      - REST_API_PORT=8511
      - MODEL_NAME=mobilenetv2
      - MODEL_BASE_PATH=/models/mobilenetv2
    ports:
      - "8510:8510"
      - "8511:8511"
    entrypoint: ["/usr/bin/tf_serving_entrypoint.sh"]

  ms_horizontal_mobilenetv2_backend:
    container_name: serving_patterns_ms_horizontal_mobilenetv2_backend
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile_backend_mobilenetv2
    environment:
      - PLATFORM=docker_compose
      - MODEL_INTERFACE=mobilenetv2.yaml
      - NUM_PROCS=4
      - BATCH_CODE=app.backend.prediction_batch
      - TFS_GRPC=ms_horizontal_mobilenetv2_tfs:8510
      - PROFILE=0
      - PREDICTOR=app.api._predict_image
      - QUEUE_NAME=mobilenetv2_queue
    command: ./run_backend.sh
    volumes:
      - shared_volume:/shared_volume
    depends_on:
      - redis

  redis:
    container_name: serving_patterns_redis
    image: "redis:latest"
    ports:
      - "6379:6379"

volumes:
  shared_volume:
    driver_opts:
      type: none
      device: /tmp
      o: bind
