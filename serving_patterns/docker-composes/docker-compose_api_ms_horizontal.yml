version: "3"

services:
  proxy_ms_h:
    container_name: serving_patterns_proxy_ms_h
    build:
      context: ..
      dockerfile: src/api_composition_proxy/Dockerfile_proxy
    environment:
      - RUNNER=GUNICORN
      - WORKERS=8
      - BACKLOG=2048
      - LIMIT_MAX_REQUESTS=65536
      - MAX_REQUESTS_JITTER=2048
      - APP_NAME=src.api_composition_proxy.apps.proxy:app
      - PORT=8000
      - PROFILE=0
      - SERVICE_WEB_SINGLE=web_single_ms_h:8888
      - SERVICE_SYNCHRONOUS=synchronous_ms_h:8889
      - SERVICE_ASYNCHRONOUS=asynchronous_ms_h:8890
      - QUEUE_NAME=api_queue
      - ENQUEUE=1
      - CUSTOMIZED_REDIRECT_MAP={"SERVICE_WEB_SINGLE":{"predict":"predict/label"},"SERVICE_SYNCHRONOUS":{"predict":"predict/label"},"SERVICE_ASYNCHRONOUS":{"predict/label":"predict"}}
    ports:
      - "8000:8000"
    command: ./run_proxy.sh

  web_single_ms_h:
    container_name: serving_patterns_web_single_ms_h
    build:
      context: ..
      dockerfile: src/app/ml/iris/Dockerfile_api_iris
    environment:
      - PLATFORM=docker_compose
      - MODEL_INTERFACE=/serving_patterns/src/app/ml/iris/model/iris_svc_sklearn.yaml
      - RUNNER=GUNICORN
      - WORKERS=4
      - BACKLOG=256
      - LIMIT_MAX_REQUESTS=1024
      - MAX_REQUESTS_JITTER=128
      - APP_NAME=src.app.apps.app_web_single:app
      - PORT=8888
      - PROFILE=0
      - QUEUE_NAME=api_queue
    ports:
      - "8888:8888"
    command: ./run_api.sh
    depends_on:
      - redis

  synchronous_ms_h:
    container_name: serving_patterns_synchronous_ms_h
    build:
      context: ..
      dockerfile: src/app/ml/iris/Dockerfile_api_iris
    environment:
      - PLATFORM=docker_compose
      - MODEL_INTERFACE=/serving_patterns/src/app/ml/iris/model/iris_svc_onnx_runtime.yaml
      - RUNNER=GUNICORN
      - WORKERS=4
      - BACKLOG=256
      - LIMIT_MAX_REQUESTS=1024
      - MAX_REQUESTS_JITTER=128
      - APP_NAME=src.app.apps.app_synchronous:app
      - PORT=8889
      - PROFILE=0
      - QUEUE_NAME=api_queue
    ports:
      - "8889:8889"
    command: ./run_api.sh
    depends_on:
      - redis

  asynchronous_ms_h:
    container_name: serving_patterns_asynchronous_ms_h
    build:
      context: ..
      dockerfile: src/app/ml/iris/Dockerfile_api_iris
    environment:
      - PLATFORM=docker_compose
      - MODEL_INTERFACE=/serving_patterns/src/app/ml/iris/model/iris_tree_onnx_runtime.yaml
      - RUNNER=GUNICORN
      - WORKERS=4
      - BACKLOG=256
      - LIMIT_MAX_REQUESTS=1024
      - MAX_REQUESTS_JITTER=128
      - APP_NAME=src.app.apps.app_asynchronous:app
      - PORT=8890
      - PROFILE=0
      - QUEUE_NAME=api_queue
    ports:
      - "8890:8890"
    command: ./run_api.sh
    depends_on:
      - api_backend_ms_h
      - redis

  api_backend_ms_h:
    container_name: serving_patterns_backend_ms_h
    build:
      context: ..
      dockerfile: src/app/ml/iris/Dockerfile_backend_iris
    environment:
      - PLATFORM=docker_compose
      - MODEL_INTERFACE=/serving_patterns/src/app/ml/iris/model/iris_tree_onnx_runtime.yaml
      - NUM_PROCS=4
      - BATCH_CODE=src.app.backend.prediction_batch
      - PROFILE=0
      - QUEUE_NAME=api_queue
    command: ./run_backend.sh
    depends_on:
      - redis

  redis:
    container_name: serving_patterns_redis
    image: "redis:latest"
    ports:
      - "6379:6379"
